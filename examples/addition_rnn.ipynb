{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 50000\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''An implementation of sequence to sequence learning for performing addition\n",
    "\n",
    "Input: \"535+61\"\n",
    "Output: \"596\"\n",
    "Padding is handled by using a repeated sentinel character (space)\n",
    "\n",
    "Input may optionally be inverted, shown to increase performance in many tasks in:\n",
    "\"Learning to Execute\"\n",
    "http://arxiv.org/abs/1410.4615\n",
    "and\n",
    "\"Sequence to Sequence Learning with Neural Networks\"\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "Theoretically it introduces shorter term dependencies between source and target.\n",
    "\n",
    "Two digits inverted:\n",
    "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "\n",
    "Three digits inverted:\n",
    "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "\n",
    "Four digits inverted:\n",
    "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "\n",
    "Five digits inverted:\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "\n",
    "\n",
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One hot encode given string C.\n",
    "\n",
    "        # Arguments\n",
    "            num_rows: Number of rows in the returned one hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)\n",
    "\n",
    "\n",
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "INVERT = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = '{}+{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "    if INVERT:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'406+766'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1172'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 7, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 4, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "これは元データを作る際に偏りが起こっているためにShuffleしているぽい\n",
    "'''\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "# Try replacing GRU, or SimpleRNN.\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 4, 12)             1548      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4, 12)             0         \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last hidden state of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(LAYERS):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 20s 441us/step - loss: 1.8862 - acc: 0.3220 - val_loss: 1.7971 - val_acc: 0.3392\n",
      "Q 13+257  T 270  \u001b[91m☒\u001b[0m 101 \n",
      "Q 536+94  T 630  \u001b[91m☒\u001b[0m 108 \n",
      "Q 24+24   T 48   \u001b[91m☒\u001b[0m 52  \n",
      "Q 89+993  T 1082 \u001b[91m☒\u001b[0m 118 \n",
      "Q 856+106 T 962  \u001b[91m☒\u001b[0m 1118\n",
      "Q 216+732 T 948  \u001b[91m☒\u001b[0m 111 \n",
      "Q 971+268 T 1239 \u001b[91m☒\u001b[0m 1118\n",
      "Q 987+60  T 1047 \u001b[91m☒\u001b[0m 108 \n",
      "Q 480+157 T 637  \u001b[91m☒\u001b[0m 111 \n",
      "Q 29+916  T 945  \u001b[91m☒\u001b[0m 101 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 20s 444us/step - loss: 1.7355 - acc: 0.3584 - val_loss: 1.6763 - val_acc: 0.3714\n",
      "Q 989+815 T 1804 \u001b[91m☒\u001b[0m 1610\n",
      "Q 592+13  T 605  \u001b[91m☒\u001b[0m 506 \n",
      "Q 45+0    T 45   \u001b[91m☒\u001b[0m 12  \n",
      "Q 916+301 T 1217 \u001b[91m☒\u001b[0m 1320\n",
      "Q 61+469  T 530  \u001b[91m☒\u001b[0m 666 \n",
      "Q 91+2    T 93   \u001b[91m☒\u001b[0m 11  \n",
      "Q 15+365  T 380  \u001b[91m☒\u001b[0m 666 \n",
      "Q 26+775  T 801  \u001b[91m☒\u001b[0m 666 \n",
      "Q 844+5   T 849  \u001b[91m☒\u001b[0m 156 \n",
      "Q 595+414 T 1009 \u001b[91m☒\u001b[0m 116 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 20s 442us/step - loss: 1.5898 - acc: 0.4035 - val_loss: 1.5213 - val_acc: 0.4245\n",
      "Q 38+946  T 984  \u001b[91m☒\u001b[0m 903 \n",
      "Q 678+45  T 723  \u001b[91m☒\u001b[0m 793 \n",
      "Q 42+700  T 742  \u001b[91m☒\u001b[0m 773 \n",
      "Q 18+271  T 289  \u001b[91m☒\u001b[0m 277 \n",
      "Q 280+23  T 303  \u001b[91m☒\u001b[0m 337 \n",
      "Q 128+45  T 173  \u001b[91m☒\u001b[0m 477 \n",
      "Q 35+711  T 746  \u001b[91m☒\u001b[0m 577 \n",
      "Q 664+85  T 749  \u001b[91m☒\u001b[0m 643 \n",
      "Q 728+829 T 1557 \u001b[91m☒\u001b[0m 1739\n",
      "Q 65+118  T 183  \u001b[91m☒\u001b[0m 217 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 24s 530us/step - loss: 1.4554 - acc: 0.4550 - val_loss: 1.3736 - val_acc: 0.4914\n",
      "Q 834+707 T 1541 \u001b[91m☒\u001b[0m 1518\n",
      "Q 9+739   T 748  \u001b[91m☒\u001b[0m 774 \n",
      "Q 207+89  T 296  \u001b[91m☒\u001b[0m 287 \n",
      "Q 466+9   T 475  \u001b[91m☒\u001b[0m 668 \n",
      "Q 36+68   T 104  \u001b[91m☒\u001b[0m 10  \n",
      "Q 28+196  T 224  \u001b[91m☒\u001b[0m 288 \n",
      "Q 735+94  T 829  \u001b[91m☒\u001b[0m 802 \n",
      "Q 99+0    T 99   \u001b[91m☒\u001b[0m 10  \n",
      "Q 67+173  T 240  \u001b[91m☒\u001b[0m 288 \n",
      "Q 87+434  T 521  \u001b[91m☒\u001b[0m 418 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 29s 643us/step - loss: 1.2970 - acc: 0.5204 - val_loss: 1.2359 - val_acc: 0.5402\n",
      "Q 36+449  T 485  \u001b[91m☒\u001b[0m 490 \n",
      "Q 201+0   T 201  \u001b[91m☒\u001b[0m 220 \n",
      "Q 382+2   T 384  \u001b[91m☒\u001b[0m 390 \n",
      "Q 0+618   T 618  \u001b[91m☒\u001b[0m 616 \n",
      "Q 199+547 T 746  \u001b[91m☒\u001b[0m 722 \n",
      "Q 1+892   T 893  \u001b[91m☒\u001b[0m 996 \n",
      "Q 493+589 T 1082 \u001b[91m☒\u001b[0m 1104\n",
      "Q 816+379 T 1195 \u001b[91m☒\u001b[0m 1256\n",
      "Q 58+12   T 70   \u001b[91m☒\u001b[0m 60  \n",
      "Q 65+241  T 306  \u001b[91m☒\u001b[0m 399 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 23s 503us/step - loss: 1.1727 - acc: 0.5671 - val_loss: 1.1168 - val_acc: 0.5903\n",
      "Q 449+529 T 978  \u001b[91m☒\u001b[0m 902 \n",
      "Q 294+7   T 301  \u001b[91m☒\u001b[0m 298 \n",
      "Q 69+938  T 1007 \u001b[91m☒\u001b[0m 101 \n",
      "Q 2+292   T 294  \u001b[91m☒\u001b[0m 291 \n",
      "Q 779+76  T 855  \u001b[91m☒\u001b[0m 854 \n",
      "Q 244+21  T 265  \u001b[91m☒\u001b[0m 263 \n",
      "Q 947+478 T 1425 \u001b[91m☒\u001b[0m 1444\n",
      "Q 203+10  T 213  \u001b[91m☒\u001b[0m 210 \n",
      "Q 17+2    T 19   \u001b[91m☒\u001b[0m 72  \n",
      "Q 3+95    T 98   \u001b[91m☒\u001b[0m 90  \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 22s 489us/step - loss: 1.0600 - acc: 0.6112 - val_loss: 0.9986 - val_acc: 0.6411\n",
      "Q 993+71  T 1064 \u001b[91m☒\u001b[0m 1066\n",
      "Q 293+863 T 1156 \u001b[91m☒\u001b[0m 1136\n",
      "Q 826+287 T 1113 \u001b[91m☒\u001b[0m 1116\n",
      "Q 241+85  T 326  \u001b[91m☒\u001b[0m 313 \n",
      "Q 70+705  T 775  \u001b[91m☒\u001b[0m 771 \n",
      "Q 200+542 T 742  \u001b[91m☒\u001b[0m 775 \n",
      "Q 21+35   T 56   \u001b[91m☒\u001b[0m 73  \n",
      "Q 825+8   T 833  \u001b[91m☒\u001b[0m 838 \n",
      "Q 30+622  T 652  \u001b[91m☒\u001b[0m 645 \n",
      "Q 171+717 T 888  \u001b[91m☒\u001b[0m 893 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 21s 463us/step - loss: 0.9562 - acc: 0.6556 - val_loss: 0.9159 - val_acc: 0.6694\n",
      "Q 61+97   T 158  \u001b[91m☒\u001b[0m 155 \n",
      "Q 106+6   T 112  \u001b[91m☒\u001b[0m 117 \n",
      "Q 80+72   T 152  \u001b[91m☒\u001b[0m 158 \n",
      "Q 21+933  T 954  \u001b[91m☒\u001b[0m 965 \n",
      "Q 84+941  T 1025 \u001b[92m☑\u001b[0m 1025\n",
      "Q 552+496 T 1048 \u001b[91m☒\u001b[0m 1148\n",
      "Q 14+740  T 754  \u001b[91m☒\u001b[0m 758 \n",
      "Q 937+54  T 991  \u001b[91m☒\u001b[0m 990 \n",
      "Q 634+42  T 676  \u001b[91m☒\u001b[0m 678 \n",
      "Q 432+161 T 593  \u001b[91m☒\u001b[0m 598 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 21s 463us/step - loss: 0.8749 - acc: 0.6882 - val_loss: 0.8611 - val_acc: 0.6795\n",
      "Q 70+210  T 280  \u001b[91m☒\u001b[0m 274 \n",
      "Q 61+185  T 246  \u001b[91m☒\u001b[0m 249 \n",
      "Q 118+987 T 1105 \u001b[91m☒\u001b[0m 1100\n",
      "Q 0+587   T 587  \u001b[91m☒\u001b[0m 589 \n",
      "Q 138+946 T 1084 \u001b[91m☒\u001b[0m 1082\n",
      "Q 891+620 T 1511 \u001b[91m☒\u001b[0m 1505\n",
      "Q 614+292 T 906  \u001b[91m☒\u001b[0m 809 \n",
      "Q 33+59   T 92   \u001b[91m☒\u001b[0m 99  \n",
      "Q 336+873 T 1209 \u001b[91m☒\u001b[0m 1200\n",
      "Q 792+71  T 863  \u001b[91m☒\u001b[0m 854 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 21s 472us/step - loss: 0.8056 - acc: 0.7175 - val_loss: 0.7882 - val_acc: 0.7216\n",
      "Q 169+702 T 871  \u001b[92m☑\u001b[0m 871 \n",
      "Q 71+751  T 822  \u001b[91m☒\u001b[0m 815 \n",
      "Q 2+384   T 386  \u001b[91m☒\u001b[0m 388 \n",
      "Q 831+22  T 853  \u001b[91m☒\u001b[0m 854 \n",
      "Q 7+967   T 974  \u001b[91m☒\u001b[0m 972 \n",
      "Q 957+10  T 967  \u001b[91m☒\u001b[0m 964 \n",
      "Q 742+972 T 1714 \u001b[91m☒\u001b[0m 1711\n",
      "Q 974+74  T 1048 \u001b[91m☒\u001b[0m 1051\n",
      "Q 38+816  T 854  \u001b[92m☑\u001b[0m 854 \n",
      "Q 569+503 T 1072 \u001b[91m☒\u001b[0m 1073\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 22s 482us/step - loss: 0.7472 - acc: 0.7375 - val_loss: 0.7131 - val_acc: 0.7481\n",
      "Q 663+25  T 688  \u001b[91m☒\u001b[0m 689 \n",
      "Q 20+455  T 475  \u001b[91m☒\u001b[0m 471 \n",
      "Q 36+37   T 73   \u001b[91m☒\u001b[0m 72  \n",
      "Q 733+69  T 802  \u001b[92m☑\u001b[0m 802 \n",
      "Q 38+651  T 689  \u001b[91m☒\u001b[0m 682 \n",
      "Q 218+9   T 227  \u001b[91m☒\u001b[0m 225 \n",
      "Q 51+588  T 639  \u001b[91m☒\u001b[0m 649 \n",
      "Q 6+940   T 946  \u001b[91m☒\u001b[0m 949 \n",
      "Q 655+64  T 719  \u001b[91m☒\u001b[0m 712 \n",
      "Q 67+9    T 76   \u001b[91m☒\u001b[0m 75  \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 21s 471us/step - loss: 0.6596 - acc: 0.7685 - val_loss: 0.6062 - val_acc: 0.7812\n",
      "Q 39+590  T 629  \u001b[91m☒\u001b[0m 638 \n",
      "Q 118+116 T 234  \u001b[91m☒\u001b[0m 231 \n",
      "Q 168+2   T 170  \u001b[92m☑\u001b[0m 170 \n",
      "Q 35+834  T 869  \u001b[91m☒\u001b[0m 868 \n",
      "Q 181+8   T 189  \u001b[91m☒\u001b[0m 188 \n",
      "Q 64+186  T 250  \u001b[91m☒\u001b[0m 245 \n",
      "Q 4+235   T 239  \u001b[91m☒\u001b[0m 249 \n",
      "Q 682+127 T 809  \u001b[91m☒\u001b[0m 811 \n",
      "Q 35+275  T 310  \u001b[91m☒\u001b[0m 312 \n",
      "Q 628+95  T 723  \u001b[92m☑\u001b[0m 723 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 21s 466us/step - loss: 0.5162 - acc: 0.8204 - val_loss: 0.4356 - val_acc: 0.8514\n",
      "Q 91+24   T 115  \u001b[91m☒\u001b[0m 114 \n",
      "Q 775+688 T 1463 \u001b[91m☒\u001b[0m 1462\n",
      "Q 866+462 T 1328 \u001b[92m☑\u001b[0m 1328\n",
      "Q 1+775   T 776  \u001b[92m☑\u001b[0m 776 \n",
      "Q 30+185  T 215  \u001b[92m☑\u001b[0m 215 \n",
      "Q 5+649   T 654  \u001b[91m☒\u001b[0m 655 \n",
      "Q 9+17    T 26   \u001b[91m☒\u001b[0m 15  \n",
      "Q 75+790  T 865  \u001b[92m☑\u001b[0m 865 \n",
      "Q 518+57  T 575  \u001b[92m☑\u001b[0m 575 \n",
      "Q 846+7   T 853  \u001b[92m☑\u001b[0m 853 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 22s 487us/step - loss: 0.3582 - acc: 0.8930 - val_loss: 0.3168 - val_acc: 0.9031\n",
      "Q 298+431 T 729  \u001b[92m☑\u001b[0m 729 \n",
      "Q 791+305 T 1096 \u001b[92m☑\u001b[0m 1096\n",
      "Q 31+42   T 73   \u001b[91m☒\u001b[0m 63  \n",
      "Q 630+31  T 661  \u001b[92m☑\u001b[0m 661 \n",
      "Q 292+683 T 975  \u001b[91m☒\u001b[0m 965 \n",
      "Q 943+209 T 1152 \u001b[92m☑\u001b[0m 1152\n",
      "Q 46+733  T 779  \u001b[92m☑\u001b[0m 779 \n",
      "Q 38+258  T 296  \u001b[91m☒\u001b[0m 386 \n",
      "Q 1+393   T 394  \u001b[92m☑\u001b[0m 394 \n",
      "Q 48+274  T 322  \u001b[92m☑\u001b[0m 322 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 20s 450us/step - loss: 0.2548 - acc: 0.9398 - val_loss: 0.2155 - val_acc: 0.9526\n",
      "Q 4+969   T 973  \u001b[92m☑\u001b[0m 973 \n",
      "Q 61+135  T 196  \u001b[92m☑\u001b[0m 196 \n",
      "Q 968+834 T 1802 \u001b[92m☑\u001b[0m 1802\n",
      "Q 53+512  T 565  \u001b[92m☑\u001b[0m 565 \n",
      "Q 41+433  T 474  \u001b[92m☑\u001b[0m 474 \n",
      "Q 885+792 T 1677 \u001b[92m☑\u001b[0m 1677\n",
      "Q 976+885 T 1861 \u001b[92m☑\u001b[0m 1861\n",
      "Q 835+925 T 1760 \u001b[91m☒\u001b[0m 1750\n",
      "Q 33+341  T 374  \u001b[92m☑\u001b[0m 374 \n",
      "Q 977+27  T 1004 \u001b[92m☑\u001b[0m 1004\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 20s 443us/step - loss: 0.1840 - acc: 0.9638 - val_loss: 0.1647 - val_acc: 0.9647\n",
      "Q 584+28  T 612  \u001b[92m☑\u001b[0m 612 \n",
      "Q 165+535 T 700  \u001b[92m☑\u001b[0m 700 \n",
      "Q 625+255 T 880  \u001b[92m☑\u001b[0m 880 \n",
      "Q 588+544 T 1132 \u001b[92m☑\u001b[0m 1132\n",
      "Q 341+78  T 419  \u001b[92m☑\u001b[0m 419 \n",
      "Q 5+202   T 207  \u001b[92m☑\u001b[0m 207 \n",
      "Q 77+37   T 114  \u001b[92m☑\u001b[0m 114 \n",
      "Q 30+675  T 705  \u001b[92m☑\u001b[0m 705 \n",
      "Q 44+29   T 73   \u001b[92m☑\u001b[0m 73  \n",
      "Q 896+822 T 1718 \u001b[91m☒\u001b[0m 1719\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 20s 449us/step - loss: 0.1330 - acc: 0.9780 - val_loss: 0.1249 - val_acc: 0.9756\n",
      "Q 814+37  T 851  \u001b[92m☑\u001b[0m 851 \n",
      "Q 831+2   T 833  \u001b[92m☑\u001b[0m 833 \n",
      "Q 38+121  T 159  \u001b[92m☑\u001b[0m 159 \n",
      "Q 42+700  T 742  \u001b[92m☑\u001b[0m 742 \n",
      "Q 218+880 T 1098 \u001b[92m☑\u001b[0m 1098\n",
      "Q 23+29   T 52   \u001b[92m☑\u001b[0m 52  \n",
      "Q 239+736 T 975  \u001b[92m☑\u001b[0m 975 \n",
      "Q 62+643  T 705  \u001b[92m☑\u001b[0m 705 \n",
      "Q 177+37  T 214  \u001b[92m☑\u001b[0m 214 \n",
      "Q 706+57  T 763  \u001b[92m☑\u001b[0m 763 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 22s 497us/step - loss: 0.1048 - acc: 0.9823 - val_loss: 0.1207 - val_acc: 0.9699\n",
      "Q 8+607   T 615  \u001b[91m☒\u001b[0m 616 \n",
      "Q 794+21  T 815  \u001b[92m☑\u001b[0m 815 \n",
      "Q 444+56  T 500  \u001b[92m☑\u001b[0m 500 \n",
      "Q 211+60  T 271  \u001b[92m☑\u001b[0m 271 \n",
      "Q 830+440 T 1270 \u001b[92m☑\u001b[0m 1270\n",
      "Q 51+369  T 420  \u001b[92m☑\u001b[0m 420 \n",
      "Q 18+21   T 39   \u001b[92m☑\u001b[0m 39  \n",
      "Q 999+403 T 1402 \u001b[91m☒\u001b[0m 1401\n",
      "Q 830+244 T 1074 \u001b[92m☑\u001b[0m 1074\n",
      "Q 20+47   T 67   \u001b[92m☑\u001b[0m 67  \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 21s 463us/step - loss: 0.0852 - acc: 0.9857 - val_loss: 0.1140 - val_acc: 0.9725\n",
      "Q 3+329   T 332  \u001b[92m☑\u001b[0m 332 \n",
      "Q 503+854 T 1357 \u001b[92m☑\u001b[0m 1357\n",
      "Q 417+2   T 419  \u001b[92m☑\u001b[0m 419 \n",
      "Q 589+66  T 655  \u001b[92m☑\u001b[0m 655 \n",
      "Q 9+393   T 402  \u001b[92m☑\u001b[0m 402 \n",
      "Q 3+943   T 946  \u001b[92m☑\u001b[0m 946 \n",
      "Q 393+2   T 395  \u001b[92m☑\u001b[0m 395 \n",
      "Q 231+919 T 1150 \u001b[92m☑\u001b[0m 1150\n",
      "Q 413+15  T 428  \u001b[92m☑\u001b[0m 428 \n",
      "Q 575+137 T 712  \u001b[92m☑\u001b[0m 712 \n"
     ]
    }
   ],
   "source": [
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for iteration in range(1, 20):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=1,\n",
    "              validation_data=(x_val, y_val))\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print('Q', q[::-1] if INVERT else q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
